{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Problem Definition\n",
    "Recurrent Neural Networks (RNNs)  have shown a lot of potential in many natural language processing (NLP) and sequence learning tasks. The main idea behind sequential learning is that they make use of sequential information. In traditional feed-forward neural networks such as Convolutional Neural Networks (CNNs), it is assumed that all inputs are independent of each other, e.g., in an image classification task, the pixels of an image are independent of each other. However, this approach is not valid for sequence learning tasks. For instance, if you want to predict the next word in a sequence (sentence), you need the prior information (i.e., previous words in the sentence) to do so. RNNs can remember previous states (information), i.e., RNNs have a “memory” in the form of hidden states which store information about what has been processed so far. At each input of the sequence, the model not only takes the current input but also remembers the preceding information. Like the human way of processing sequential information, this allows the model to learn long-term dependencies in the sequence, i.e., it considers the entire context when making a prediction. \n",
    "\n",
    "Prediction of the next alarm can also be modelled as a sequence learning task: given a sorted sequence of alarms based on their start time, predict the upcoming alarm. In this report, we compared a RNN architecture and a Transfomrer architecture in terms of accuracy of predicitng next alarm. \n",
    "\n",
    "By predicting future alarms in real-time with the help of the AI module, the operator may avert abnormal situations by taking corrective actions or prepare for such situations in advance.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# # for logging \n",
    "\n",
    "from comet_ml import Experiment\n",
    "from pytorch_lightning.loggers import CometLogger\n",
    "from pytorch_lightning.loggers import TestTubeLogger\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "import wandb\n",
    "\n",
    "# For metrics\n",
    "from pytorch_lightning import metrics\n",
    "\n",
    "import math\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import io\n",
    "import torchtext\n",
    "from torchtext.utils import download_from_url, extract_archive\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.trainer.trainer import Trainer\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping # The EarlyStopping callback can be used to monitor a validation metric and stop the training when no improvement is observed.\n",
    "\"\"\"\n",
    "    To enable it:\n",
    "\n",
    "    Import EarlyStopping callback.\n",
    "\n",
    "    Log the metric you want to monitor using log() method.\n",
    "\n",
    "    Init the callback, and set monitor to the logged metric of your choice.\n",
    "\n",
    "    Pass the EarlyStopping callback to the Trainer callbacks flag.\n",
    "\"\"\"\n",
    "\n",
    "from pytorch_lightning import seed_everything\n",
    "seed_everything(42)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Performance Metrics"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from pytorch_lightning.metrics import Metric\n",
    "from pytorch_lightning.metrics.utils import _input_format_classification\n",
    "from sklearn.metrics import classification_report\n",
    "class MyClassificationReport(Metric):\n",
    "    def __init__(self,threshold: float = 0.5,compute_on_step: bool = True,dist_sync_on_step: bool = False):\n",
    "        super().__init__(\n",
    "            compute_on_step=compute_on_step,\n",
    "            dist_sync_on_step=dist_sync_on_step,\n",
    "        )\n",
    "\n",
    "        self.threshold = threshold\n",
    "        self.add_state(\"preds\", default=[], dist_reduce_fx=None)\n",
    "        self.add_state(\"target\", default=[], dist_reduce_fx=None)\n",
    "\n",
    "        # rank_zero_warn(\n",
    "        #     'Metric `MyClassificationReport` will save all targets and predictions in buffer.'\n",
    "        #     ' For large datasets this may lead to large memory footprint.'\n",
    "        # )\n",
    "\n",
    "    def update(self, preds: torch.Tensor, target: torch.Tensor):\n",
    "        preds = preds.cpu()\n",
    "        target = target.cpu()\n",
    "        y_hat, y = preds.max(1).indices, target\n",
    "        assert y_hat.shape == y.shape\n",
    "        self.preds.append(y_hat)\n",
    "        self.target.append(y)\n",
    "\n",
    "    def compute(self):\n",
    "        preds = torch.cat(self.preds, dim=0)\n",
    "        target = torch.cat(self.target, dim=0)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Dataset Prepartion"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "class AlarmDataset(Dataset):\n",
    "    def __init__(self,data,seq_len,batch_size):\n",
    "        self.length = len(data)//seq_len # how much data i have         \n",
    "        self.data = data\n",
    "        self.seq_len = seq_len\n",
    "        self.batch_size = batch_size\n",
    "       \n",
    "    def __getitem__(self, index: int):\n",
    "        x = self.data[index*self.seq_len:(index*self.seq_len)+self.seq_len]\n",
    "        y = self.data[1+index*self.seq_len:1+(index*self.seq_len)+self.seq_len]\n",
    "        return x,y\n",
    "    \n",
    "    def __len__(self) -> int:\n",
    "        return self.length\n",
    "\n",
    "class MyDataModule(pl.LightningDataModule):\n",
    "    \n",
    "    def __init__(self,config):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        dir_path = self.config['dir-path']\n",
    "        file_name = 'train.tokens'\n",
    "\n",
    "        self.tokenizer = get_tokenizer('basic_english')\n",
    "        self.vocab = build_vocab_from_iterator(map(self.tokenizer,iter(io.open(dir_path+file_name,encoding=\"utf8\"))))\n",
    "    \n",
    "\n",
    "        train_data = self.data_process(iter(io.open(dir_path +\"train.tokens\", encoding=\"utf8\")))\n",
    "        val_data = self.data_process(iter(io.open(dir_path +\"val.tokens\", encoding=\"utf8\")))\n",
    "        test_data = self.data_process(iter(io.open(dir_path +\"test.tokens\", encoding=\"utf8\")))\n",
    "\n",
    "    \n",
    "        self.train_dataset = AlarmDataset(train_data, self.config['seq-len'], self.config['batch-size'])\n",
    "        self.valid_dataset = AlarmDataset(val_data,self.config['seq-len'], self.config['batch-size'])\n",
    "        self.test_dataset = AlarmDataset(test_data, self.config['seq-len'], self.config['batch-size'])\n",
    "\n",
    "    \n",
    "    def data_process(self, raw_text_iter):\n",
    "        data = [torch.tensor([self.vocab[token] for token in self.tokenizer(item)],dtype=torch.long) for item in raw_text_iter]\n",
    "        return torch.cat(tuple(filter(lambda t: t.numel() > 0, data)))\n",
    "    \n",
    "    def get_weight_per_class(self):\n",
    "        def lambdaFun(total,v,num_classes):\n",
    "            if v>0:\n",
    "                return total/(v*num_classes) \n",
    "            return 0\n",
    "        \n",
    "        index_2_count = {self.vocab.stoi[k]:self.vocab.freqs[k]  for k in list(self.vocab.stoi)}\n",
    "        total = sum(index_2_count.values())\n",
    "        index_2_ws = {k:lambdaFun(total,v,len(index_2_count)) for k,v in index_2_count.items()}\n",
    "        index_2_ws[1] = 0.0 # MANUALLY Setting the weights to zero for the padding\n",
    "        # index_2_ws[0] = 0.0 # MANUALLY Setting the weights to zero for the padding\n",
    "        ws = torch.tensor([index_2_ws[i] for i in range(len(index_2_ws))])\n",
    "\n",
    "        return ws\n",
    "\n",
    "    def prepare_data(self):\n",
    "        \"\"\"\n",
    "            Use this method to do things that might write to disk or that need to be done only from a single GPU in distributed settings.\n",
    "            e.g., download,tokenize,etc…\n",
    "        \"\"\" \n",
    "        return None\n",
    "\n",
    "\n",
    "    def setup(self, stage: None):\n",
    "        \"\"\"\n",
    "            There are also data operations you might want to perform on every GPU. Use setup to do things like:\n",
    "            count number of classes,build vocabulary,perform train/val/test splits,apply transforms (defined explicitly in your datamodule or assigned in init),etc…\n",
    "        \"\"\"\n",
    "        return None\n",
    "\n",
    "    def train_dataloader(self) -> DataLoader:\n",
    "        return DataLoader(self.train_dataset, batch_size=self.config['batch-size'], shuffle=False,num_workers=8,drop_last=True, pin_memory=True)\n",
    "    \n",
    "    def val_dataloader(self) -> DataLoader:\n",
    "        return DataLoader(self.valid_dataset, batch_size=self.config['batch-size'], shuffle=False,num_workers=8,drop_last=True, pin_memory=True)\n",
    "    \n",
    "    def test_dataloader(self) -> DataLoader:\n",
    "        return DataLoader(self.test_dataset, batch_size=self.config['batch-size'], shuffle=False,num_workers=8,drop_last=True, pin_memory=True)\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Transformer Model\n",
    "\n",
    "The alarm modeling task is to assign a\n",
    "probability for the likelihood of a given sequence of words\n",
    "to follow a next alarm. A sequence of tokens are passed to the embedding\n",
    "layer first, followed by a positional encoding layer to account for the order\n",
    "of the word. The\n",
    "``nn.TransformerEncoder`` consists of multiple layers of\n",
    "`nn.TransformerEncoderLayer <https://pytorch.org/docs/master/nn.html?highlight=transformerencoderlayer#torch.nn.TransformerEncoderLayer>`__. Along with the input sequence, a square\n",
    "attention mask is required because the self-attention layers in\n",
    "``nn.TransformerEncoder`` are only allowed to attend the earlier positions in\n",
    "the sequence. For the language modeling task, any tokens on the future\n",
    "positions should be masked. To have the actual alarms, the output\n",
    "of ``nn.TransformerEncoder`` model is sent to the final Linear\n",
    "layer, which is followed by a log-Softmax function.\n",
    "\n",
    "\n",
    "# Positional Encoding\n",
    "\n",
    "``PositionalEncoding`` module injects some information about the\n",
    "relative or absolute position of the tokens (i.e.,) in the sequence. The\n",
    "positional encodings have the same dimension as the embeddings so that\n",
    "the two can be summed. Here, we use ``sine`` and ``cosine`` functions of\n",
    "different frequencies.\n",
    "\n",
    "# Loss Function\n",
    "\n",
    "`CrossEntropyLoss` is applied to track the loss and `AdamW`implements stochastic gradient descent method as the optimizer.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "class PositionalEncoding(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = torch.nn.Dropout(p=dropout)\n",
    "\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:x.size(0), :]\n",
    "        return self.dropout(x)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Transformer Architecture"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "class TransformerModel(pl.LightningModule):\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super(TransformerModel, self).__init__()\n",
    "        self.accuraccy_50_count = 0\n",
    "        self.config = config        \n",
    "        self.lr = self.config[\"lr\"]\n",
    "        self.weight_decay = self.config[\"weight-decay\"]\n",
    "    \n",
    "        self.pos_encoder = PositionalEncoding(self.config['em-size'], self.config['dropout'])\n",
    "        encoder_layers = torch.nn.TransformerEncoderLayer(self.config['em-size'], self.config['nhead'], self.config['nhid'], self.config[\"dropout\"])\n",
    "        self.transformer_encoder = torch.nn.TransformerEncoder(encoder_layers, self.config['nlayers'])\n",
    "        self.encoder = torch.nn.Embedding(self.config[\"vocab-size\"], self.config['em-size'])\n",
    "        self.decoder = torch.nn.Linear(self.config['em-size'], self.config[\"vocab-size\"])\n",
    "        self.src_mask = self.generate_square_subsequent_mask(self.config['seq-len'])\n",
    "        self.init_weights()\n",
    "\n",
    "        self.class_weight = self.config['weight_per_class']\n",
    "\n",
    "        # self.train_F1 = metrics.classification.F1(num_classes=self.config[\"vocab-size\"],average = 'micro')\n",
    "        # self.val_F1 = metrics.classification.F1(num_classes=self.config[\"vocab-size\"],average = 'micro')\n",
    "        # self.test_F1 = metrics.classification.F1(num_classes=self.config[\"vocab-size\"],average = 'micro')\n",
    "        \n",
    "        self.val_CM_normalized = metrics.classification.ConfusionMatrix(num_classes=self.config[\"vocab-size\"],normalize ='true')\n",
    "        self.val_CM_raw = metrics.classification.ConfusionMatrix(num_classes=self.config[\"vocab-size\"])\n",
    "\n",
    "        self.train_CM_normalized = metrics.classification.ConfusionMatrix(num_classes=self.config[\"vocab-size\"],normalize ='true')\n",
    "        self.train_CM_raw = metrics.classification.ConfusionMatrix(num_classes=self.config[\"vocab-size\"])\n",
    "\n",
    "        self.test_CM = metrics.classification.ConfusionMatrix(num_classes=self.config[\"vocab-size\"],normalize ='true')\n",
    "\n",
    "        self.val_MCR = MyClassificationReport()\n",
    "        self.test_MCR = MyClassificationReport()\n",
    "\n",
    "        self.log(\"Sequence length\",self.config['seq-len'])\n",
    "        self.log(\"lr\",self.lr)\n",
    "        self.log(\"# of tokens/vocab_size (unique alarms)\",self.config['vocab-size'])\n",
    "        self.log(\"weight_decay\",self.weight_decay)\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "    def generate_square_subsequent_mask(self, sz):\n",
    "        mask = (torch.triu(torch.ones(sz, sz)) == 1).transpose(0, 1)\n",
    "        mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
    "        return mask\n",
    "\n",
    "    def init_weights(self): # initialize the weights to non zero number\n",
    "        initrange = 0.1\n",
    "        self.encoder.weight.data.uniform_(-initrange, initrange)\n",
    "        self.decoder.bias.data.zero_()\n",
    "        self.decoder.weight.data.uniform_(-initrange, initrange)\n",
    "\n",
    "    def forward(self, src, src_mask):\n",
    "        src_mask = src_mask.to(self.device)\n",
    "        src = self.encoder(src) * math.sqrt(self.config['em-size'])\n",
    "        src = self.pos_encoder(src)\n",
    "      \n",
    "        output = self.transformer_encoder(src, src_mask)\n",
    "        output = self.decoder(output)\n",
    "        \n",
    "        return output\n",
    "\n",
    "   # The ReduceLROnPlateau scheduler requires a monitor\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.AdamW(self.parameters(), lr=self.lr,weight_decay=self.weight_decay)\n",
    "        d = {\n",
    "       'optimizer': optimizer,\n",
    "       'lr_scheduler': torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode = \"min\", factor = 0.5, patience=10, verbose=True),\n",
    "       'monitor': 'val_epoch_loss',\n",
    "        'interval': 'epoch'\n",
    "        }\n",
    "        return d \n",
    "\n",
    "    def loss_function(self,logits,y):\n",
    "        return F.cross_entropy(logits,y,weight= self.class_weight,ignore_index=1) \n",
    "\n",
    "    def myPrintToFile(self,cm_normal,cm_raw,f):\n",
    "        cm_normal = cm_normal.cpu()\n",
    "        cm_raw = cm_raw.cpu()\n",
    "        \n",
    "\n",
    "        sum_of_each_class = cm_raw.sum(axis=1) # sum along the columns\n",
    "        print(f\"        ------ Epoch {self.current_epoch} ---------\",file=f)\n",
    "        print(f\"Total={[v.item() for v in sum_of_each_class]}\",file=f)\n",
    "        print(f\"Corret={[v.item() for v in torch.diagonal(cm_raw,0)]}\",file=f)\n",
    "        print(f\"Accuracy={[round(v.item(),3) for v in (torch.diagonal(cm_raw,0)/sum_of_each_class)]}\",file=f)\n",
    "\n",
    "        accs = [round(v.item(),3)  for v in torch.diagonal(cm_normal,0)]\n",
    "\n",
    "        source2acc = {self.config['vocab'].itos[i]:accs[i] for i in range(len(accs))}\n",
    "\n",
    "        source2_acc50 = {self.config['vocab'].itos[i]:accs[i] for i in range(len(accs)) if accs[i]>=0.5}\n",
    "\n",
    "        print(f\"Acc2={accs}\",file=f)\n",
    "        print(f\"source2_acc= {source2acc}\",file=f)\n",
    "        print(f\"source2_acc50= {source2_acc50}\",file=f)\n",
    "\n",
    "        a_50 = len([a for a in accs if a>=0.5])\n",
    "        a_30 = len([a for a in accs if a>=0.3])\n",
    "        out_str = f\"acc>0.5= {a_50}, acc>=0.3= {a_30}, Total={len(accs)}\"\n",
    "        print(out_str,file=f)\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "        # if temp> self.accuraccy_50_count and train=:\n",
    "        #     self.accuraccy_50_count = temp\n",
    "        print(out_str,end=\" \") \n",
    "\n",
    "      \n",
    "\n",
    "    def training_step(self,batch,batch_idx):\n",
    "        x,y = batch\n",
    "        x = x.T # transpose\n",
    "        y = y.T.reshape(-1)\n",
    "\n",
    "        if x.size(0) != self.config['seq-len']:\n",
    "           self.src_mask =  self.generate_square_subsequent_mask(x.size(0))\n",
    "        \n",
    "        y_hat = self(x,self.src_mask) # calling forward method\n",
    "        y_hat =  y_hat.view(-1, self.config['vocab-size'])\n",
    "        loss = self.loss_function(y_hat,y) # cross entropy itself compute softmax \n",
    "\n",
    "        self.train_CM_normalized(F.softmax(y_hat),y)\n",
    "        self.train_CM_raw(F.softmax(y_hat),y)\n",
    "        \n",
    "        self.log('train_loss',loss,logger=True)\n",
    "        # self.log('train_F1',self.train_F1(F.softmax(y_hat),y),logger=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self,batch, batch_idx):\n",
    "        x,y = batch\n",
    "        x = x.T\n",
    "        y = y.T.reshape(-1)\n",
    "        \n",
    "        if x.size(0) != self.config['seq-len']:\n",
    "            # print(f\">> passed {x.size()}\")\n",
    "            self.src_mask =  self.generate_square_subsequent_mask(x.size(0))\n",
    "        \n",
    "        y_hat = self(x,self.src_mask)\n",
    "        y_hat =  y_hat.view(-1, self.config['vocab-size'])\n",
    "        loss = self.loss_function(y_hat,y)\n",
    "\n",
    "        self.val_MCR(F.softmax(y_hat),y)\n",
    "        self.val_CM_normalized(F.softmax(y_hat),y)\n",
    "        self.val_CM_raw(F.softmax(y_hat),y)\n",
    "\n",
    "        self.log('val_loss',loss,logger=True)\n",
    "        # self.log('val_F1',self.val_F1(F.softmax(y_hat) ,y),logger=True)\n",
    "        return {'val_loss':loss}\n",
    "    \n",
    "    def test_step(self,batch, batch_idx):\n",
    "        x,y = batch\n",
    "        x = x.T\n",
    "        y = y.T.reshape(-1)\n",
    "        if x.size(0) != self.config['seq-len']:\n",
    "           self.src_mask =  self.generate_square_subsequent_mask(x.size(0))\n",
    "\n",
    "        y_hat = self(x,self.src_mask)\n",
    "        y_hat =  y_hat.view(-1,  self.config['vocab-size'])\n",
    "        loss = self.loss_function(y_hat,y)\n",
    "\n",
    "        self.test_MCR(F.softmax(y_hat),y)\n",
    "        self.log('test_loss',loss,logger=True)\n",
    "        # self.log('test_F1', self.test_F1(F.softmax(y_hat) ,y),logger=True)\n",
    "        return {'test_loss':loss}\n",
    "    \n",
    "    def training_epoch_end(self, outputs):\n",
    "\n",
    "        avg_loss = torch.stack([d['loss']  for d in outputs]).mean()\n",
    "        # f1 = self.train_F1.compute()\n",
    "        print(f\"[{self.current_epoch}]E, Avg Training loss = {round(avg_loss.item(),4)}\",end=\" \")\n",
    "        \n",
    "        with open(self.config[\"train-file\"],'a') as f:\n",
    "            self.myPrintToFile(self.train_CM_normalized.compute(),self.train_CM_raw.compute(),f)\n",
    "        self.log(\"train_epoch_loss\",avg_loss,logger=True,prog_bar=True)\n",
    "        # self.log(\"train_epoch_F1\", f1, logger=True,prog_bar=True)\n",
    "  \n",
    "    def validation_epoch_end(self, outputs):\n",
    "        avg_loss = torch.stack([d['val_loss'] for d in outputs]).mean()\n",
    "        # f1 = self.val_F1.compute()\n",
    "        # print(self.val_MCR.compute(),file=open(\"val-out.txt\",'w'))\n",
    "        # print(self.val_CM.compute(),file=open(\"val-cm-out.txt\",'w'))\n",
    "\n",
    "        # if self.current_epoch%4==0 and self.current_epoch>0:\n",
    "        # self.myPrintToFile(self.val_CM_normalized.compute(),self.val_CM_raw.compute())\n",
    "\n",
    "\n",
    "        print(f\"::Val Loss = {round(avg_loss.item(),4) }\",end=\" \")\n",
    "\n",
    "        with open(self.config[\"val-file\"],'a') as f:\n",
    "            self.myPrintToFile(self.val_CM_normalized.compute(),self.val_CM_raw.compute(),f)\n",
    "        \n",
    "        print(\"\")\n",
    "\n",
    "\n",
    "        self.log(\"val_epoch_loss\",avg_loss,logger=True)\n",
    "        # self.log(\"val_epoch_F1\",f1,logger=True,prog_bar=True)\n",
    "    \n",
    "    def test_epoch_end(self, outputs):\n",
    "        avg_loss = torch.stack([d['test_loss'] for d in outputs]).mean()\n",
    "        # f1 = self.test_F1.compute()\n",
    "        # print(self.test_MCR.compute(),file=open(\"test-out.txt\",'w'))\n",
    "        print(f\">Average Test Loss = {avg_loss.item()}\")\n",
    "        self.log(\"test_epoch_loss\",avg_loss, logger = True)\n",
    "        # self.log(\"test_epoch_F1\",f1, logger=True)\n",
    "        \n",
    "    "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# RNN Architecture"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "class AlarmGRU(pl.LightningModule):\n",
    "    \n",
    "    def __init__(self,config):\n",
    "        # super().__init__()\n",
    "        super(AlarmGRU,self).__init__()\n",
    "        self.config =config\n",
    "        self.lr = self.config['lr']\n",
    "        \n",
    "\n",
    "        self.val_CM_normalized = metrics.classification.ConfusionMatrix(num_classes=self.config[\"vocab-size\"],normalize ='true')\n",
    "        self.val_CM_raw = metrics.classification.ConfusionMatrix(num_classes=self.config[\"vocab-size\"])\n",
    "\n",
    "        self.train_CM_normalized = metrics.classification.ConfusionMatrix(num_classes=self.config[\"vocab-size\"],normalize ='true')\n",
    "        self.train_CM_raw = metrics.classification.ConfusionMatrix(num_classes=self.config[\"vocab-size\"])\n",
    "\n",
    "        self.test_CM = metrics.classification.ConfusionMatrix(num_classes=self.config[\"vocab-size\"],normalize ='true')\n",
    "\n",
    "        self.val_MCR = MyClassificationReport()\n",
    "        self.test_MCR = MyClassificationReport()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        ## TODO: define the layers of the model\n",
    "        self.h = None\n",
    "        self.embedding = torch.nn.Embedding(self.config['vocab-size'],self.config['em-size'])\n",
    "        self.gru = torch.nn.GRU(input_size=self.config['em-size'], hidden_size=self.config['nhid'], num_layers=self.config['nlayers'],dropout=self.config['dropout'], batch_first=True)\n",
    "        # self.droput = torch.nn.Dropout(p=self.drop_prob)\n",
    "        self.fc3 = torch.nn.Linear(in_features=self.config['nhid'], out_features=self.config['vocab-size'])\n",
    "        self.softmax = torch.nn.LogSoftmax(dim=1)  \n",
    "    \n",
    "    def __init_hidden(self):\n",
    "        ''' Initializes hidden state '''\n",
    "        # Create two new tensors with sizes n_layers x batch_size x n_hidden,\n",
    "        # initialized to zero, for hidden state and cell state of GRU\n",
    "        device = None \n",
    "        if (torch.cuda.is_available()):\n",
    "            device = torch.device(\"cuda\")\n",
    "        else:\n",
    "            device = torch.device(\"cpu\") \n",
    "        \n",
    "        weight = next(self.parameters()).data\n",
    "        hidden = weight.new(self.config['nlayers'], self.config['batch-size'], self.config['nhid']).zero_().to(device)\n",
    "        return hidden\n",
    "\n",
    "    def initialize_hidden(self):\n",
    "        self.h = self.__init_hidden()\n",
    "    \n",
    "    def forward(self, x, hidden):\n",
    "        ''' Forward pass through the network. \n",
    "            These inputs are x, and the hidden/cell state `hidden`. '''\n",
    "                \n",
    "        ## TODO: Get the outputs and the new hidden state from the lstm\n",
    "        x = x.long()\n",
    "        embeds = self.embedding(x)\n",
    "        out, hidden = self.gru(embeds,hidden)\n",
    "        out = out.contiguous().view(-1,self.config['nhid']) \n",
    "        out = self.fc3(out)\n",
    "        out = self.softmax(out)\n",
    "        # return the final output and the hidden state\n",
    "        return out, hidden\n",
    "        \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.AdamW(self.parameters(), lr=self.lr,weight_decay=self.config['weight-decay'])\n",
    "        d = {\n",
    "       'optimizer': optimizer,\n",
    "       'lr_scheduler': torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode = \"min\", factor = 0.5, patience=10, verbose=True),\n",
    "       'monitor': 'val_epoch_loss',\n",
    "        'interval': 'epoch'\n",
    "        }\n",
    "        return d\n",
    "\n",
    "    # def loss_function(self,logits,y):\n",
    "    #     return F.cross_entropy(logits,y,weight= self.class_weight,ignore_index=1) \n",
    "\n",
    "    def myPrintToFile(self,cm_normal,cm_raw,f):\n",
    "        cm_normal = cm_normal.cpu()\n",
    "        cm_raw = cm_raw.cpu()\n",
    "        \n",
    "\n",
    "        sum_of_each_class = cm_raw.sum(axis=1) # sum along the columns\n",
    "        print(f\"        ------ Epoch {self.current_epoch} ---------\",file=f)\n",
    "        print(f\"Total={[v.item() for v in sum_of_each_class]}\",file=f)\n",
    "        print(f\"Corret={[v.item() for v in torch.diagonal(cm_raw,0)]}\",file=f)\n",
    "        print(f\"Accuracy={[round(v.item(),3) for v in (torch.diagonal(cm_raw,0)/sum_of_each_class)]}\",file=f)\n",
    "\n",
    "        accs = [round(v.item(),3)  for v in torch.diagonal(cm_normal,0)]\n",
    "\n",
    "        source2acc = {self.config['vocab'].itos[i]:accs[i] for i in range(len(accs))}\n",
    "\n",
    "        source2_acc50 = {self.config['vocab'].itos[i]:accs[i] for i in range(len(accs)) if accs[i]>=0.5}\n",
    "\n",
    "        print(f\"Acc2={accs}\",file=f)\n",
    "        print(f\"source2_acc= {source2acc}\",file=f)\n",
    "        print(f\"source2_acc50= {source2_acc50}\",file=f)\n",
    "\n",
    "        a_50 = len([a for a in accs if a>=0.5])\n",
    "        a_30 = len([a for a in accs if a>=0.3])\n",
    "        out_str = f\"acc>0.5= {a_50}, acc>=0.3= {a_30}, Total={len(accs)}\"\n",
    "        print(out_str,file=f)\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "        # if temp> self.accuraccy_50_count and train=:\n",
    "        #     self.accuraccy_50_count = temp\n",
    "        print(out_str,end=\" \")\n",
    "    \n",
    "    \n",
    "    def training_step(self,batch,batch_idx):\n",
    "        x,y = batch\n",
    "        y =  y.view(self.config['batch-size']*self.config['seq-len']).long()\n",
    "\n",
    "        self.h = self.h.data # for GRU\n",
    "        y_hat, self.h = self(x,self.h)\n",
    "        #  ignore_index=self.char2int[\"NoName\"]\n",
    "        loss = F.nll_loss(y_hat,y)\n",
    "        \n",
    "        self.train_CM_normalized(y_hat,y)\n",
    "        self.train_CM_raw(y_hat,y)    \n",
    "        # result = pl.TrainResult(loss) # logging\n",
    "        self.log('train_loss',loss,logger=True)\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self,batch, batch_idx):\n",
    "        x,y = batch\n",
    "        y =  y.view(self.config['batch-size']*self.config['seq-len']).long()\n",
    "\n",
    "        self.h = self.h.data # for GRU\n",
    "        y_hat, self.h = self(x,self.h)\n",
    "        #  ignore_index=self.char2int[\"NoName\"]\n",
    "        loss = F.nll_loss(y_hat,y)\n",
    "        \n",
    "        self.val_CM_normalized(y_hat,y)\n",
    "        self.val_CM_raw(y_hat,y)\n",
    "        self.log('val_loss',loss,logger=True)\n",
    "        return {'val_loss':loss}\n",
    "    \n",
    "    def test_step(self,batch, batch_idx):\n",
    "        x,y = batch\n",
    "        y =  y.view(self.config['batch-size']*self.config['seq-len']).long()\n",
    "\n",
    "        self.h = self.h.data # for GRU\n",
    "        y_hat, self.h = self(x,self.h)\n",
    "        #  ignore_index=self.char2int[\"NoName\"]\n",
    "        loss = F.nll_loss(y_hat,y)\n",
    "        \n",
    "        self.val_CM_normalized(y_hat,y)\n",
    "        self.val_CM_raw(y_hat,y)\n",
    "        self.log('test_loss',loss,logger=True)\n",
    "        return {'test_loss':loss}\n",
    "    \n",
    "    def training_epoch_end(self, outputs):\n",
    "\n",
    "        avg_loss = torch.stack([d['loss']  for d in outputs]).mean()\n",
    "        # f1 = self.train_F1.compute()\n",
    "        print(f\"[{self.current_epoch}]E, Avg Training loss = {round(avg_loss.item(),4)}\",end=\" \")\n",
    "        \n",
    "        with open(self.config[\"train-file\"],'a') as f:\n",
    "            self.myPrintToFile(self.train_CM_normalized.compute(),self.train_CM_raw.compute(),f)\n",
    "        self.log(\"train_epoch_loss\",avg_loss,logger=True,prog_bar=True)\n",
    "        # self.log(\"train_epoch_F1\", f1, logger=True,prog_bar=True)\n",
    "    \n",
    "    def validation_epoch_end(self, outputs):\n",
    "        avg_loss = torch.stack([d['val_loss'] for d in outputs]).mean()\n",
    "        # f1 = self.val_F1.compute()\n",
    "        # print(self.val_MCR.compute(),file=open(\"val-out.txt\",'w'))\n",
    "        # print(self.val_CM.compute(),file=open(\"val-cm-out.txt\",'w'))\n",
    "\n",
    "        # if self.current_epoch%4==0 and self.current_epoch>0:\n",
    "        # self.myPrintToFile(self.val_CM_normalized.compute(),self.val_CM_raw.compute())\n",
    "\n",
    "\n",
    "        print(f\"::Val Loss = {round(avg_loss.item(),4) }\",end=\" \")\n",
    "\n",
    "        with open(self.config[\"val-file\"],'a') as f:\n",
    "            self.myPrintToFile(self.val_CM_normalized.compute(),self.val_CM_raw.compute(),f)\n",
    "        \n",
    "        print(\"\")\n",
    "\n",
    "\n",
    "        self.log(\"val_epoch_loss\",avg_loss,logger=True)\n",
    "        # self.log(\"val_epoch_F1\",f1,logger=True,prog_bar=True)\n",
    "\n",
    "    def test_epoch_end(self, outputs):\n",
    "        avg_loss = torch.stack([d['test_loss'] for d in outputs]).mean()\n",
    "        # f1 = self.test_F1.compute()\n",
    "        # print(self.test_MCR.compute(),file=open(\"test-out.txt\",'w'))\n",
    "        print(f\">Average Test Loss = {avg_loss.item()}\")\n",
    "        self.log(\"test_epoch_loss\",avg_loss, logger = True)\n",
    "        # self.log(\"test_epoch_F1\",f1, logger=True)\n",
    "    \n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Trainning Transformers\n",
    "\n",
    "**Note: When monitoring any parameter after the validation epoch end then you should pass check_val_every_n_epoch=1  not to other. This is very important.**\n",
    "\n",
    "### Finding the learning rate for the Transformer model."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def weightCondition(w,avg_w):\n",
    "    if w<avg_w:\n",
    "        return w\n",
    "    else:\n",
    "        return avg_w\n",
    "\n",
    "# setup data\n",
    "config_data = {\n",
    "'dir-path' : \"../.data/\",\n",
    "'batch-size' :512, # Batch Size \n",
    "'seq-len' :12, # Sequence length\n",
    "}\n",
    "\n",
    "dm = MyDataModule(config=config_data)\n",
    "ws = dm.get_weight_per_class().cuda()\n",
    "\n",
    "print(\"Before\",[round(w.item(),3) for w in ws])\n",
    "# avg_w = sum(ws)/len(ws)\n",
    "# ws = torch.tensor([weightCondition(w,avg_w) for w in ws]).cuda()\n",
    "print(\"After\",[round(w.item(),3) for w in ws])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "config_model = {\n",
    "    'lr' : 0.001,\n",
    "    'dropout' : 0.2,\n",
    "    'weight-decay': 3.1,\n",
    "    'em-size' :256, # embedding dimension \n",
    "    'nhid' : 128, # the dimension of the feedforward network model in nn.TransformerEncoder\n",
    "    'nlayers' :4, # the number of nn.TransformerEncoderLayer in nn.TransformerEncoder\n",
    "    'nhead' : 2, # the number of heads in the multiheadattention models\n",
    "    'seq-len': config_data['seq-len'], # dont use wandb config \n",
    "    'vocab-size':len(dm.vocab.stoi), # the size of vocabulary /also called tokens\n",
    "    'weight_per_class':ws,\n",
    "    \"val-file\":\"val-out.txt\",\n",
    "    \"train-file\":'train-out.txt',\n",
    "    \"vocab\": dm.vocab\n",
    "}\n",
    "\n",
    "with open (config_model[\"val-file\"],'w') as f:\n",
    "    f.write(\">> Starting\")\n",
    "\n",
    "with open (config_model[\"train-file\"],'w') as f:\n",
    "    f.write(\">> Starting\")\n",
    "\n",
    "# setup model - note how we refer to sweep parameters with wandb.config\n",
    "model = TransformerModel(config=config_model)\n",
    "\n",
    "early_stop_callback = EarlyStopping(\n",
    "        monitor='val_epoch_loss',\n",
    "        min_delta=0,\n",
    "        patience=600,\n",
    "        verbose=True,\n",
    "        mode='min'\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "trainer = Trainer(auto_lr_find=0.0001, precision=16,gpus=-1, num_nodes=1,  max_epochs=100, check_val_every_n_epoch=1,deterministic=True,gradient_clip_val=0.5,enable_pl_optimizer=True,callbacks=[early_stop_callback],progress_bar_refresh_rate=0)\n",
    "\n",
    "# Run learning rate finder\n",
    "lr_finder = trainer.tuner.lr_find(model,dm)\n",
    "\n",
    "# Results can be found in\n",
    "lr_finder.results\n",
    "\n",
    "# Plot with\n",
    "fig = lr_finder.plot(suggest=True)\n",
    "fig.show()\n",
    "\n",
    "# Pick point based on plot, or get suggestion\n",
    "new_lr = lr_finder.suggestion()\n",
    "\n",
    "print(f\"Suggested lr = {new_lr}\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model.hparams.lr = new_lr/100 #7.5e-12 # can devide by 10\n",
    "\n",
    "trainer.fit(model,dm) # Fit model\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# trainer.test(datamodule=dm) # testing"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Traninng RNNs\n",
    "Finding the learning rate for the RNN model. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# setup data\n",
    "config_data = {\n",
    "'dir-path' : \"../.data/\",\n",
    "'batch-size' :512, # Batch Size \n",
    "'seq-len' :128, # Sequence length change to 6\n",
    "}\n",
    "\n",
    "dm = MyDataModule(config=config_data)\n",
    "ws = dm.get_weight_per_class().cuda()\n",
    "\n",
    "print(\"Before\",[round(w.item(),3) for w in ws])\n",
    "# avg_w = sum(ws)/len(ws)\n",
    "# ws = torch.tensor([weightCondition(w,avg_w) for w in ws]).cuda()\n",
    "print(\"After\",[round(w.item(),3) for w in ws])\n",
    "\n",
    "\n",
    "config_model = {\n",
    "    'lr' : 0.001,\n",
    "    'dropout' : 0.05,\n",
    "    'weight-decay': 3.1, #3.1,\n",
    "    'em-size' :256, # embedding dimension \n",
    "    'nhid' : 512, # the dimension of the feedforward network model in nn.TransformerEncoder\n",
    "    'nlayers' :3, # the number of nn.TransformerEncoderLayer in nn.TransformerEncoder\n",
    "    'seq-len': config_data['seq-len'], # dont use wandb config \n",
    "    'vocab-size':len(dm.vocab.stoi), # the size of vocabulary /also called tokens\n",
    "    'weight_per_class':ws,\n",
    "    \"val-file\":\"val-out-rnn.txt\",\n",
    "    \"train-file\":'train-out-rnn.txt',\n",
    "    \"vocab\": dm.vocab,\n",
    "    \"batch-size\":config_data['batch-size']\n",
    "}\n",
    "\n",
    "with open (config_model[\"val-file\"],'w') as f:\n",
    "    f.write(\">> Starting\")\n",
    "\n",
    "with open (config_model[\"train-file\"],'w') as f:\n",
    "    f.write(\">> Starting\")\n",
    "\n",
    "\n",
    "\n",
    "model = AlarmGRU(config=config_model)\n",
    "model.initialize_hidden()\n",
    "\n",
    "early_stop_callback = EarlyStopping(\n",
    "        monitor='val_epoch_loss',\n",
    "        min_delta=0,\n",
    "        patience=100,\n",
    "        verbose=True,\n",
    "        mode='min'\n",
    ")\n",
    "\n",
    "\n",
    "trainer = Trainer(auto_lr_find=0.0001, precision=16,gpus=-1, num_nodes=1,  max_epochs=100, check_val_every_n_epoch=1,deterministic=True,gradient_clip_val=0.5,enable_pl_optimizer=True,callbacks=[early_stop_callback],progress_bar_refresh_rate=0)\n",
    "\n",
    "# Run learning rate finder\n",
    "lr_finder = trainer.tuner.lr_find(model,dm)\n",
    "\n",
    "# Results can be found in\n",
    "lr_finder.results\n",
    "\n",
    "# Plot with\n",
    "fig = lr_finder.plot(suggest=True)\n",
    "fig.show()\n",
    "\n",
    "# Pick point based on plot, or get suggestion\n",
    "new_lr = lr_finder.suggestion()\n",
    "\n",
    "print(f\"Suggested lr = {new_lr}\")\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model.hparams.lr = new_lr/100 #7.5e-12 # can devide by 10\n",
    "trainer.fit(model,dm) # Fit model\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# trainer.test(datamodule=dm) # testing"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Conclusion\n",
    "\n",
    "As we can see from the above outputs, in 100 epochs the Transformers models predict roughly more than 135 alarms sources with more than 50% accuracy while RNN model only able to predict 51 alrarm sources with more than 50% accuracy. Thus, the Transformers performs relative better as compared to RNNs on next alarm prediction task. \n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8076afad8c2f739e22f417bad77704dbad7b0389c4d6903b1ae4a1b7479f7ed3"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('dl': conda)",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}