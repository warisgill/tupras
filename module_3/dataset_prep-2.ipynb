{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from datetime import timedelta\n",
    "import time\n",
    "import numpy as np\n",
    "from functools import partial\n",
    "from sklearn.model_selection import train_test_split\n",
    "import itertools\n",
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "from functools import partial\n",
    "import itertools\n",
    "\n",
    "from multiprocessing import Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCol2Count(df,col):\n",
    "    return dict(df[col].value_counts())\n",
    "    \n",
    "def __removeChatteringAlarmsHelper(alarms,chattering_timedelta_threshold, chattering_count_threshold):\n",
    "        \"\"\"Find the chatterings in an alarms list from the same source.  \n",
    "        \"\"\"\n",
    "\n",
    "        alarms_without_chattering = []\n",
    "        alarms = [alarm for alarm in sorted(alarms, key=lambda arg: arg[\"StartTime\"], reverse=False)]\n",
    "        i = 0\n",
    "        j = 0\n",
    "\n",
    "        while i < (len(alarms)):\n",
    "            alarms_without_chattering.append(alarms[i])\n",
    "            prev_start = alarms[i][\"StartTime\"]\n",
    "            prev_end = alarms[i][\"EndTime\"]\n",
    "            count_alarms = 0\n",
    "            j = i + 1\n",
    "            while j < len(alarms):\n",
    "                next_start = alarms[j][\"StartTime\"]\n",
    "                next_end = alarms[j][\"EndTime\"]\n",
    "\n",
    "                # this assert is very important: the prev alarm has to turn off before the start of\n",
    "                # the next one\n",
    "                assert(prev_start <= next_start)\n",
    "                assert(prev_end <= next_start)\n",
    "                assert(prev_end <= next_end)\n",
    "\n",
    "                delta = timedelta.total_seconds(next_start - prev_start)\n",
    "                assert (delta >= 0)\n",
    "                \n",
    "                if delta > chattering_timedelta_threshold:\n",
    "                    break\n",
    "                count_alarms += 1\n",
    "                \n",
    "                j += 1\n",
    "            \n",
    "            if count_alarms >= chattering_count_threshold:\n",
    "                i = j\n",
    "            else:\n",
    "                i += 1\n",
    "\n",
    "        return alarms_without_chattering\n",
    "    \n",
    "def tempFun(df,chat_delta,chat_count,sname):\n",
    "\n",
    "    alarms_without_chatterings = []\n",
    "    df_source = df.loc[df['SourceName'].isin([sname])]\n",
    "\n",
    "    for condition in df_source[\"Condition\"].unique():\n",
    "        df_condition = df_source.loc[df_source['Condition'].isin([condition])]\n",
    "        alarms = __removeChatteringAlarmsHelper(df_condition.to_dict(orient=\"records\"),chattering_timedelta_threshold=chat_delta,chattering_count_threshold=chat_count)\n",
    "        alarms_without_chatterings = alarms_without_chatterings + alarms\n",
    "    \n",
    "    return alarms_without_chatterings\n",
    "\n",
    "def removeChatteringAlarms(df,chattering_timedelta_threshold=None,chat_count=None):\n",
    "\n",
    "    # for sname in df[\"SourceName\"].unique():\n",
    "\n",
    "    alarms_without_chatterings = [] \n",
    "    sources=[sname for sname in df[\"SourceName\"].unique()] \n",
    "\n",
    "    myFun =  partial(tempFun,df,chattering_timedelta_threshold,chat_count)\n",
    "    \n",
    "\n",
    "    with Pool(3) as p:\n",
    "        alarms_without_chatterings = p.map(myFun, sources)\n",
    "\n",
    "    alarms_without_chatterings = list(itertools.chain.from_iterable(alarms_without_chatterings))\n",
    "    return pd.DataFrame(alarms_without_chatterings)\n",
    "\n",
    "\n",
    "\n",
    "class AlarmsProcessing:\n",
    "    def __init__(self,config) -> None:\n",
    "        self.config = config\n",
    "        self.alias2name = None\n",
    "        self.name2alias = None\n",
    "        self.df = pd.read_csv(self.config['file-path'], low_memory=False, usecols=self.config['usecols'],parse_dates=self.config['date-cols'])\n",
    "        if self.config['alias']:\n",
    "            self.convertSourceNamesToAlias()\n",
    "        \n",
    "        for m in self.df[\"Year-Month\"].unique():\n",
    "            \n",
    "            month_df = self.df[self.df[\"Year-Month\"].isin([m])].sort_values(by='StartTime', ascending=True).reset_index(drop=True)\n",
    "\n",
    "            days = sorted(list(month_df['Day'].unique()))\n",
    "            print(f\"[{m}],Days:{days}\")\n",
    "    \n",
    "    def convertSourceNamesToAlias(self):\n",
    "        alias2name = {f\"A{k}\": v for k, v in enumerate(self.df[\"SourceName\"].unique())}\n",
    "        name2alias = {v: k for k, v in alias2name.items()}\n",
    "        self.df[\"SourceName\"] = self.df[\"SourceName\"].apply(lambda sname: name2alias[sname])\n",
    "        self.alias2name = alias2name\n",
    "        self.name2alias = name2alias\n",
    "        # return name2alias, alias2name\n",
    "\n",
    "    def removeChatteringAlarms(self,df,chattering_timedelta_threshold=60,chattering_count_threshold=2):\n",
    "        return removeChatteringAlarms(df=df,chattering_timedelta_threshold=chattering_timedelta_threshold,chat_count=chattering_count_threshold)\n",
    "\n",
    "    def removeMomentaryAlarms(self,df,monmentarly_filter=None):\n",
    "        df = df[(df[\"TimeDelta\"] > monmentarly_filter)].reset_index(drop=True)\n",
    "        return df\n",
    "\n",
    "    def removeStalingAlarms(self,df,staling_filter=None):\n",
    "        df =  df[(df[\"TimeDelta\"] < staling_filter)].reset_index(drop=True)\n",
    "        return df\n",
    "\n",
    "    def removeConditionsAlarms(self,df,conditions_filter):\n",
    "        df = df[~df[\"Condition\"].isin(conditions_filter)].reset_index(drop=True)\n",
    "        return df\n",
    "\n",
    "    def removeSources(self,df, sources_filter):\n",
    "        df = df[(~df[\"SourceName\"].isin(sources_filter))].reset_index(drop=True)\n",
    "        return df\n",
    "    \n",
    "    def removeSourcesBasedOnMinCount(self,df,min_alarms_per_source_filter):\n",
    "        source2count = dict(df[\"SourceName\"].value_counts())\n",
    "        select_sources = [k for k, v in source2count.items() if v >= min_alarms_per_source_filter]\n",
    "        df = df[df[\"SourceName\"].isin(select_sources)]\n",
    "        return df\n",
    "\n",
    "    def getDFWithCommonSourcesInAllMonths(self,df):\n",
    "        each_month_source_names = [[sname for sname in df[df[\"Year-Month\"]==month][\"SourceName\"].unique()] for month in df[\"Year-Month\"].unique()]\n",
    "        common_sourcenames_in_all_months = set.intersection(*[set(l) for l in each_month_source_names])\n",
    "        df = df[df[\"SourceName\"].isin(common_sourcenames_in_all_months)]\n",
    "        return df\n",
    "      \n",
    "    def updatSourceNamewithCondition(self,df):\n",
    "        def _concatenateSourceNameAndCondition(sname, condition):\n",
    "            return sname+\"-\"+condition\n",
    "        df[\"SourceName\"] = df[[\"SourceName\", \"Condition\"]].apply(\n",
    "            lambda arg: _concatenateSourceNameAndCondition(*arg), axis=1)\n",
    "        return df\n",
    "    \n",
    "    def getCondition2Sources(self,df,condition):\n",
    "        return df[df[\"Condition\"]==condition][\"SourceName\"].unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrepareDataset:\n",
    "    def __init__(self,config) -> None:\n",
    "        self.config = config\n",
    "\n",
    "    def getSeqsFromAlarmsDF(self,df,seq_duration_gap,filter_short_seq):\n",
    "        print(f\">> Duration to next seq: {seq_duration_gap}, ignore seq len: {filter_short_seq}\")\n",
    "\n",
    "        list_of_sequences = []    \n",
    "        alarms= df.sort_values(by='StartTime', ascending=True).reset_index(drop=True).to_dict(orient=\"records\")\n",
    "        alarms = [alarm for alarm in sorted(alarms, key=lambda arg: arg[\"StartTime\"], reverse=False)] # sorting\n",
    "\n",
    "        # print('check',len(alarms))\n",
    "        assert alarms[0]['StartTime'] < alarms[-1]['StartTime']\n",
    "        i =0\n",
    "        j= 0\n",
    "\n",
    "        max_seq_len = -1\n",
    "        while i <len(alarms):\n",
    "            prev_start = alarms[i][\"StartTime\"]\n",
    "            seq = []\n",
    "            seq.append(alarms[i])\n",
    "            j = i+1\n",
    "            while j < len(alarms):    \n",
    "                next_start = alarms[j][\"StartTime\"]\n",
    "                delta = timedelta.total_seconds(next_start - prev_start)\n",
    "                # print(delta)\n",
    "                assert delta >= 0\n",
    "                if delta >= seq_duration_gap:\n",
    "                    break\n",
    "\n",
    "                seq.append(alarms[j])\n",
    "                j += 1\n",
    "            i = j\n",
    "\n",
    "            if len(seq) > max_seq_len:\n",
    "                max_seq_len = len(seq)\n",
    "            \n",
    "            if len(seq)>=filter_short_seq:\n",
    "                seq = [alarm for alarm in sorted(seq, key=lambda arg: arg[\"StartTime\"], reverse=False)]\n",
    "                seq = [alarm[\"SourceName\"] for alarm in seq]\n",
    "                list_of_sequences.append(seq)\n",
    "        \n",
    "        \n",
    "        return list_of_sequences, max_seq_len\n",
    "\n",
    "\n",
    "    def splitDFtoTrainValidDfsPerMonthByRows(self,df,p=0.2):    \n",
    "        tarain_dfs = []\n",
    "        valid_dfs = []\n",
    "        for m in df[\"Year-Month\"].unique():\n",
    "            \n",
    "            month_df = df[(df[\"Year-Month\"].isin([m]))].sort_values(by='StartTime', ascending=True).reset_index(drop=True)\n",
    "\n",
    "            train_df = month_df[0:int(len(month_df)*(1-p))]\n",
    "            train_df = train_df.reset_index(drop=True)\n",
    "            valid_df = month_df[int(len(month_df)*(1-p)):]\n",
    "            valid_df = valid_df.reset_index(drop=True)\n",
    "            assert len(train_df)+len(valid_df) == len(month_df)\n",
    "            tarain_dfs.append(train_df)\n",
    "            valid_dfs.append(valid_df)\n",
    "        \n",
    "        t_df = pd.concat(tarain_dfs, ignore_index=True).sort_values(by='StartTime', ascending=True).reset_index(drop=True)\n",
    "        v_df = pd.concat(valid_dfs, ignore_index=True).sort_values(by='StartTime', ascending=True).reset_index(drop=True)\n",
    "\n",
    "        assert len(t_df)+len(v_df) == len(df) \n",
    "\n",
    "        return t_df, v_df\n",
    "    \n",
    "    def splitDFtoTrainValidDfsPerMonthByDays(self,df,p=0.2):    \n",
    "        tarain_dfs = []\n",
    "        valid_dfs = []\n",
    "        for m in df[\"Year-Month\"].unique():\n",
    "            \n",
    "            month_df = df[(df[\"Year-Month\"].isin([m]))].sort_values(by='StartTime', ascending=True).reset_index(drop=True)\n",
    "\n",
    "            days = sorted(list(month_df['Day'].unique()))\n",
    "            # if len(days)<5:\n",
    "            #     print(f\"Skipping : [{m}],Days:{days}\")\n",
    "            #     continue\n",
    "            \n",
    "            print(f\"[{m}]: Days: {days}\")\n",
    "\n",
    "            train_days = days[0:len(days)-int(len(days)*p)]\n",
    "            valid_days = days[len(days)-int(len(days)*p):len(days)]\n",
    "            # print(f\"[{m}]Train Days: {train_days}, val days = {valid_days} \")\n",
    "\n",
    "            train_df = month_df[month_df['Day'].isin(train_days)].reset_index(drop=True)\n",
    "            valid_df = month_df[month_df['Day'].isin(valid_days)].reset_index(drop=True)\n",
    "\n",
    "            assert len(train_df)+len(valid_df) == len(month_df)\n",
    "            tarain_dfs.append(train_df)\n",
    "            valid_dfs.append(valid_df)\n",
    "        \n",
    "        t_df = pd.concat(tarain_dfs, ignore_index=True).sort_values(by='StartTime', ascending=True).reset_index(drop=True)\n",
    "        v_df = pd.concat(valid_dfs, ignore_index=True).sort_values(by='StartTime', ascending=True).reset_index(drop=True)\n",
    "\n",
    "        # assert len(t_df)+len(v_df) == len(df) \n",
    "\n",
    "        return t_df, v_df\n",
    "    \n",
    "    def writeSequeces2TokenFile(self,file_path,li_of_seqs):\n",
    "        with open(file_path,\"w\") as f:\n",
    "            for seq in li_of_seqs:\n",
    "                f.write(f\"{' '.join(seq)}\\n\")\n",
    "        \n",
    "        print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(2019, 3)],Days:[6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23]\n",
      "[(2020, 9)],Days:[1, 2, 3, 4, 5, 6, 8, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30]\n",
      "[(2019, 5)],Days:[31]\n",
      "[(2019, 6)],Days:[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]\n",
      "[(2020, 10)],Days:[1, 2, 3, 4, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31]\n",
      "[(2020, 7)],Days:[1, 2, 5, 6, 7, 9, 10, 11, 12, 13, 14, 15, 16, 17, 19, 20, 22, 23, 26, 27, 28, 30, 31]\n",
      "[(2020, 3)],Days:[1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 13, 14, 15, 16, 17, 18, 19, 21, 22]\n",
      "[(2020, 11)],Days:[1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13, 14, 15, 16, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]\n",
      "[(2019, 10)],Days:[1, 2, 3, 4, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31]\n",
      "[(2019, 4)],Days:[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]\n",
      "[(2020, 2)],Days:[1, 2, 4, 5, 6, 7, 8, 9, 10, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29]\n",
      "[(2019, 11)],Days:[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 22, 24, 25, 26, 27, 28, 29, 30]\n",
      "[(2019, 7)],Days:[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31]\n",
      "[(2019, 8)],Days:[1, 2, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 19, 20, 21, 22, 23, 25, 26, 27, 28, 29, 30, 31]\n",
      "[(2019, 12)],Days:[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 31]\n",
      "[(2018, 1)],Days:[4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31]\n",
      "[(2018, 2)],Days:[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28]\n",
      "[(2018, 4)],Days:[1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 25]\n",
      "[(2018, 6)],Days:[1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]\n",
      "[(2018, 7)],Days:[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31]\n",
      "[(2018, 8)],Days:[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31]\n",
      "[(2018, 9)],Days:[1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]\n",
      "[(2018, 10)],Days:[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
      "[(2018, 3)],Days:[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]\n",
      "[(2018, 5)],Days:[8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31]\n",
      "[(2020, 12)],Days:[2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31]\n",
      "[(2020, 4)],Days:[2, 3, 4, 5, 6, 7, 13, 14, 17, 18, 21, 22, 23, 26]\n",
      "[(2020, 1)],Days:[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 30, 31]\n",
      "[(2020, 6)],Days:[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 16, 17, 18, 19, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]\n",
      "[(2019, 9)],Days:[1, 2, 3, 4, 5, 6, 9, 10, 11, 12, 13, 14, 15, 17, 18, 19, 22, 23, 24, 25, 26, 27, 28, 30]\n",
      "[(2020, 5)],Days:[4, 5, 6, 8, 9, 12, 14, 15, 16, 17, 18, 23, 25, 26, 27, 28, 29, 30, 31]\n",
      "[(2020, 8)],Days:[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]\n",
      "Total Time to load the data  3.123283386230469e-05\n"
     ]
    },
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>SourceName</th>\n      <th>Condition</th>\n      <th>StartTime</th>\n      <th>EndTime</th>\n      <th>TimeDelta</th>\n      <th>Year-Month</th>\n      <th>Day</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>47TI931A</td>\n      <td>IOP</td>\n      <td>2019-03-06 13:19:17</td>\n      <td>2019-03-06 13:19:33</td>\n      <td>16.0</td>\n      <td>(2019, 3)</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>47TI931A</td>\n      <td>IOP</td>\n      <td>2019-03-06 13:19:35</td>\n      <td>2019-03-06 13:20:22</td>\n      <td>47.0</td>\n      <td>(2019, 3)</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>47TI931A</td>\n      <td>IOP</td>\n      <td>2019-03-06 13:20:24</td>\n      <td>2019-03-06 13:20:28</td>\n      <td>4.0</td>\n      <td>(2019, 3)</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>47TI931A</td>\n      <td>IOP</td>\n      <td>2019-03-06 13:20:30</td>\n      <td>2019-03-06 13:20:49</td>\n      <td>19.0</td>\n      <td>(2019, 3)</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>47TI931A</td>\n      <td>IOP</td>\n      <td>2019-03-06 13:20:51</td>\n      <td>2019-03-06 13:21:03</td>\n      <td>12.0</td>\n      <td>(2019, 3)</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>23435875</th>\n      <td>47HCD-046H-ANN</td>\n      <td>ALM</td>\n      <td>2020-08-20 08:58:39</td>\n      <td>2020-08-20 09:02:07</td>\n      <td>208.0</td>\n      <td>(2020, 8)</td>\n      <td>20</td>\n    </tr>\n    <tr>\n      <th>23435876</th>\n      <td>47LI951</td>\n      <td>LO</td>\n      <td>2020-08-12 22:51:27</td>\n      <td>2020-08-13 15:46:05</td>\n      <td>60878.0</td>\n      <td>(2020, 8)</td>\n      <td>12</td>\n    </tr>\n    <tr>\n      <th>23435877</th>\n      <td>47XL1525A-ANN</td>\n      <td>ALM</td>\n      <td>2020-08-22 11:40:12</td>\n      <td>2020-08-22 11:41:22</td>\n      <td>70.0</td>\n      <td>(2020, 8)</td>\n      <td>22</td>\n    </tr>\n    <tr>\n      <th>23435878</th>\n      <td>47FIC2026</td>\n      <td>LO</td>\n      <td>2020-08-21 11:50:10</td>\n      <td>2020-08-21 11:50:38</td>\n      <td>28.0</td>\n      <td>(2020, 8)</td>\n      <td>21</td>\n    </tr>\n    <tr>\n      <th>23435879</th>\n      <td>47HSD-050HH-ANN</td>\n      <td>ALM</td>\n      <td>2020-08-20 09:10:42</td>\n      <td>2020-08-20 09:27:19</td>\n      <td>997.0</td>\n      <td>(2020, 8)</td>\n      <td>20</td>\n    </tr>\n  </tbody>\n</table>\n<p>23435880 rows × 7 columns</p>\n</div>",
      "text/plain": "               SourceName Condition           StartTime             EndTime  \\\n0                47TI931A       IOP 2019-03-06 13:19:17 2019-03-06 13:19:33   \n1                47TI931A       IOP 2019-03-06 13:19:35 2019-03-06 13:20:22   \n2                47TI931A       IOP 2019-03-06 13:20:24 2019-03-06 13:20:28   \n3                47TI931A       IOP 2019-03-06 13:20:30 2019-03-06 13:20:49   \n4                47TI931A       IOP 2019-03-06 13:20:51 2019-03-06 13:21:03   \n...                   ...       ...                 ...                 ...   \n23435875   47HCD-046H-ANN       ALM 2020-08-20 08:58:39 2020-08-20 09:02:07   \n23435876          47LI951        LO 2020-08-12 22:51:27 2020-08-13 15:46:05   \n23435877    47XL1525A-ANN       ALM 2020-08-22 11:40:12 2020-08-22 11:41:22   \n23435878        47FIC2026        LO 2020-08-21 11:50:10 2020-08-21 11:50:38   \n23435879  47HSD-050HH-ANN       ALM 2020-08-20 09:10:42 2020-08-20 09:27:19   \n\n          TimeDelta Year-Month  Day  \n0              16.0  (2019, 3)    6  \n1              47.0  (2019, 3)    6  \n2               4.0  (2019, 3)    6  \n3              19.0  (2019, 3)    6  \n4              12.0  (2019, 3)    6  \n...             ...        ...  ...  \n23435875      208.0  (2020, 8)   20  \n23435876    60878.0  (2020, 8)   12  \n23435877       70.0  (2020, 8)   22  \n23435878       28.0  (2020, 8)   21  \n23435879      997.0  (2020, 8)   20  \n\n[23435880 rows x 7 columns]"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = {\n",
    "    'file-path': \"../.data/plant_old_0/final/all-months-alarms-2.csv\",\n",
    "    'usecols':[\"SourceName\", \"Condition\", \"StartTime\",\"EndTime\",\"TimeDelta\",\"Year-Month\",'Day'],\n",
    "    'date-cols':   [\"StartTime\", \"EndTime\"],\n",
    "    'alias': False\n",
    "}\n",
    "\n",
    "alarm = AlarmsProcessing(config=config)\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "print(\"Total Time to load the data \", time.time()-start)\n",
    "\n",
    "alarm.df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "{'VEL+': 6430189,\n 'VEL-': 5980640,\n 'IOP': 5799390,\n 'IOP-': 1593252,\n 'ALM': 1068186,\n 'LLL': 499375,\n 'LO': 491399,\n 'LL': 389725,\n 'CNF': 345639,\n 'LTRP': 303890,\n 'HI': 159705,\n 'HHH': 118648,\n 'CERR': 91462,\n 'HTRP': 82014,\n 'HH': 32309,\n 'ANS-': 26819,\n 'DV+': 9173,\n 'DV-': 7409,\n 'MLO': 2498,\n 'OVR': 1107,\n 'OOP': 858,\n 'PERR': 803,\n 'ANS+': 577,\n 'PWON': 380,\n 'MHI': 335,\n 'TRIP': 98}"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "con2count=getCol2Count(df=alarm.df,col='Condition')\n",
    "con2count\n",
    "\n",
    "#Important  Trip, HHH, HTRP, LTRP, LLL, -> most imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "{'ALM': 1068186,\n 'LLL': 499375,\n 'LO': 491399,\n 'LL': 389725,\n 'CNF': 345639,\n 'LTRP': 303890,\n 'HI': 159705,\n 'HHH': 118648,\n 'CERR': 91462,\n 'HTRP': 82014,\n 'HH': 32309,\n 'ANS-': 26819,\n 'DV+': 9173,\n 'DV-': 7409,\n 'MLO': 2498,\n 'OVR': 1107,\n 'OOP': 858,\n 'PERR': 803,\n 'ANS+': 577,\n 'PWON': 380,\n 'MHI': 335,\n 'TRIP': 98}"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove communication alarms\n",
    "df = alarm.removeConditionsAlarms(df=alarm.df,conditions_filter=[\"IOP\", \"IOP-\",'VEL-','VEL+'])\n",
    "con2count=getCol2Count(df=df,col='Condition')\n",
    "con2count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "{'CNF': 345291,\n 'ALM': 312587,\n 'LO': 288305,\n 'LL': 211213,\n 'HI': 121881,\n 'LLL': 118982,\n 'LTRP': 59327,\n 'HTRP': 45074,\n 'HHH': 44148,\n 'ANS-': 26703,\n 'HH': 26206,\n 'CERR': 16894,\n 'DV+': 8841,\n 'DV-': 7140,\n 'MLO': 2391,\n 'OVR': 1107,\n 'OOP': 707,\n 'PERR': 555,\n 'ANS+': 553,\n 'PWON': 380,\n 'MHI': 335,\n 'TRIP': 88}"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = alarm.removeChatteringAlarms(df=df,chattering_timedelta_threshold=60,chattering_count_threshold=3)\n",
    "con2count=getCol2Count(df=df,col='Condition')\n",
    "con2count\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df3 = alarm.removeConditionsAlarms(df=alarm.df,conditions_filter=[\"IOP\", \"IOP-\",'VEL+','VEL-'])\n",
    "# con2count=getCol2Count(df=df3,col='Condition')\n",
    "# print(con2count)\n",
    "# df4 = removeChatteringAlarms(df=df3,chattering_timedelta_threshold=60, chat_count =2)\n",
    "# con2count=getCol2Count(df=df4,col='Condition')\n",
    "# con2count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total = 0\n",
    "# for cond,count in getCol2Count(df=df,col='Condition').items(): \n",
    "#     l = df[df['Condition']==cond][\"SourceName\"].unique()\n",
    "#     total += len(l)\n",
    "\n",
    "#     print(f\">>{cond},{count},{len(l)}\")\n",
    "\n",
    "\n",
    "# print(len(getCol2Count(df,col='SourceName')),total)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>CNF,344479,22\n",
      ">>ALM,299784,135\n",
      ">>LO,283989,323\n",
      ">>LL,209710,270\n",
      ">>HI,119062,328\n",
      ">>LLL,117247,137\n",
      ">>LTRP,57813,133\n",
      ">>HTRP,43741,58\n",
      ">>HHH,42063,71\n",
      ">>ANS-,26399,6\n",
      ">>HH,25309,230\n",
      ">>CERR,16866,12\n",
      ">>DV+,8742,75\n",
      ">>DV-,7027,77\n",
      ">>MLO,2386,13\n",
      ">>ANS+,433,6\n",
      ">>OOP,394,82\n",
      ">>MHI,294,17\n",
      ">>PERR,113,3\n",
      ">>TRIP,88,1\n",
      "725 1999\n"
     ]
    }
   ],
   "source": [
    "df2 = alarm.removeSourcesBasedOnMinCount(df,min_alarms_per_source_filter=70)\n",
    "total = 0\n",
    "for cond,count in getCol2Count(df=df2,col='Condition').items(): \n",
    "    l = df2[df2['Condition']==cond][\"SourceName\"].unique()\n",
    "    total += len(l)\n",
    "\n",
    "    print(f\">>{cond},{count},{len(l)}\")\n",
    "\n",
    "\n",
    "print(len(getCol2Count(df2,col='SourceName')),total)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp_sources = []\n",
    "\n",
    "# for s in df[\"SourceName\"].unique():\n",
    "#     # print(len(df2[df2['SourceName']==s]['Condition'].unique()))\n",
    "#     if len(df[df['SourceName']==s]['Condition'].unique())==1:\n",
    "#         temp_sources.append(s)\n",
    "\n",
    "\n",
    "# print(temp_sources)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(2019, 3)]: Days: [6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23]\n",
      "[(2019, 4)]: Days: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]\n",
      "[(2019, 6)]: Days: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]\n",
      "[(2019, 7)]: Days: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31]\n",
      "[(2019, 10)]: Days: [1, 2, 3, 4, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31]\n",
      "[(2019, 12)]: Days: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 31]\n",
      "[(2020, 7)]: Days: [1, 2, 5, 6, 7, 9, 10, 11, 12, 13, 14, 15, 16, 17, 19, 20, 22, 23, 26, 27, 28, 30, 31]\n",
      "[(2020, 8)]: Days: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]\n",
      "[(2020, 10)]: Days: [1, 2, 3, 4, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31]\n",
      "[(2020, 11)]: Days: [1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13, 14, 15, 16, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]\n",
      "[(2020, 12)]: Days: [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31]\n",
      "[(2019, 8)]: Days: [1, 2, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 19, 20, 21, 22, 23, 25, 26, 27, 28, 29, 30, 31]\n",
      "[(2020, 1)]: Days: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 30, 31]\n",
      "[(2020, 5)]: Days: [4, 5, 6, 8, 9, 12, 14, 15, 16, 17, 18, 23, 25, 26, 27, 28, 29, 30, 31]\n",
      "[(2018, 5)]: Days: [8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31]\n",
      "[(2018, 6)]: Days: [1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]\n",
      "[(2018, 7)]: Days: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31]\n",
      "[(2018, 8)]: Days: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31]\n",
      "[(2018, 9)]: Days: [1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]\n",
      "[(2018, 10)]: Days: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
      "[(2019, 5)]: Days: [31]\n",
      "[(2019, 9)]: Days: [1, 2, 3, 4, 5, 6, 9, 10, 11, 12, 13, 14, 15, 17, 18, 19, 22, 23, 24, 25, 26, 27, 28, 30]\n",
      "[(2020, 2)]: Days: [1, 2, 4, 5, 6, 7, 8, 9, 10, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29]\n",
      "[(2020, 3)]: Days: [1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 13, 14, 15, 16, 17, 18, 19, 21, 22]\n",
      "[(2020, 4)]: Days: [2, 3, 4, 5, 6, 7, 13, 14, 17, 18, 21, 22, 23, 26]\n",
      "[(2020, 6)]: Days: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 16, 17, 18, 19, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]\n",
      "[(2018, 1)]: Days: [4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31]\n",
      "[(2018, 2)]: Days: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28]\n",
      "[(2018, 3)]: Days: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]\n",
      "[(2018, 4)]: Days: [1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 25]\n",
      "[(2019, 11)]: Days: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 22, 24, 25, 26, 27, 28, 29, 30]\n",
      "[(2020, 9)]: Days: [1, 2, 3, 4, 5, 6, 8, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30]\n",
      "[(2018, 1)]: Days: [24, 25, 26, 27, 28, 29, 30, 31]\n",
      "[(2018, 2)]: Days: [21, 22, 23, 24, 25, 26, 27, 28]\n",
      "[(2018, 3)]: Days: [23, 24, 25, 26, 27, 28, 29, 30]\n",
      "[(2018, 4)]: Days: [19, 20, 21, 22, 23, 25]\n",
      "[(2018, 5)]: Days: [26, 27, 28, 29, 30, 31]\n",
      "[(2018, 6)]: Days: [23, 24, 25, 26, 27, 28, 29, 30]\n",
      "[(2018, 7)]: Days: [23, 24, 25, 26, 27, 28, 29, 30, 31]\n",
      "[(2018, 8)]: Days: [23, 24, 25, 26, 27, 28, 29, 30, 31]\n",
      "[(2018, 9)]: Days: [23, 24, 25, 26, 27, 28, 29, 30]\n",
      "[(2018, 10)]: Days: [9, 10, 11]\n",
      "[(2019, 3)]: Days: [19, 20, 21, 22, 23]\n",
      "[(2019, 4)]: Days: [23, 24, 25, 26, 27, 28, 29, 30]\n",
      "[(2019, 6)]: Days: [23, 24, 25, 26, 27, 28, 29, 30]\n",
      "[(2019, 7)]: Days: [23, 24, 25, 26, 27, 28, 29, 30, 31]\n",
      "[(2019, 8)]: Days: [25, 26, 27, 28, 29, 30, 31]\n",
      "[(2019, 9)]: Days: [23, 24, 25, 26, 27, 28, 30]\n",
      "[(2019, 10)]: Days: [23, 24, 25, 26, 27, 28, 29, 30, 31]\n",
      "[(2019, 11)]: Days: [22, 24, 25, 26, 27, 28, 29, 30]\n",
      "[(2019, 12)]: Days: [23, 24, 25, 26, 27, 28, 29, 31]\n",
      "[(2020, 1)]: Days: [23, 24, 25, 27, 28, 29, 30, 31]\n",
      "[(2020, 2)]: Days: [22, 23, 24, 25, 26, 28, 29]\n",
      "[(2020, 3)]: Days: [17, 18, 19, 21, 22]\n",
      "[(2020, 4)]: Days: [21, 22, 23, 26]\n",
      "[(2020, 5)]: Days: [27, 28, 29, 30, 31]\n",
      "[(2020, 6)]: Days: [23, 24, 25, 26, 27, 28, 29, 30]\n",
      "[(2020, 7)]: Days: [23, 26, 27, 28, 30, 31]\n",
      "[(2020, 8)]: Days: [22, 23, 24, 25, 26, 27, 28, 29, 30]\n",
      "[(2020, 9)]: Days: [22, 23, 24, 25, 26, 27, 29, 30]\n",
      "[(2020, 10)]: Days: [24, 25, 26, 27, 28, 29, 30, 31]\n",
      "[(2020, 11)]: Days: [23, 24, 25, 26, 27, 28, 29, 30]\n",
      "[(2020, 12)]: Days: [23, 24, 25, 26, 27, 28, 29, 30, 31]\n",
      ">> Duration to next seq: 900, ignore seq len: 0\n",
      ">> Duration to next seq: 900, ignore seq len: 0\n",
      ">> Duration to next seq: 900, ignore seq len: 0\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "DataSet is complete\n"
     ]
    }
   ],
   "source": [
    "\n",
    "FINAL_DF = df2\n",
    "\n",
    "\n",
    "alarm_dataset = PrepareDataset({})\n",
    "train_df, valid_df = alarm_dataset.splitDFtoTrainValidDfsPerMonthByDays(FINAL_DF,p=0.3)\n",
    "valid_df, test_df = alarm_dataset.splitDFtoTrainValidDfsPerMonthByDays(valid_df,p=0.2)\n",
    "\n",
    "seqs_train, _  = alarm_dataset.getSeqsFromAlarmsDF(train_df,seq_duration_gap=60*15,filter_short_seq=0)\n",
    "seqs_valid, _  = alarm_dataset.getSeqsFromAlarmsDF(valid_df,seq_duration_gap=60*15,filter_short_seq=0)\n",
    "seqs_test, _  = alarm_dataset.getSeqsFromAlarmsDF(test_df,seq_duration_gap=60*15,filter_short_seq=0)\n",
    "\n",
    "alarm_dataset.writeSequeces2TokenFile(file_path=\"../.data/train.tokens\",li_of_seqs=seqs_train)\n",
    "alarm_dataset.writeSequeces2TokenFile(file_path=\"../.data/val.tokens\",li_of_seqs=seqs_valid)\n",
    "alarm_dataset.writeSequeces2TokenFile(file_path=\"../.data/test.tokens\",li_of_seqs=seqs_test)\n",
    "\n",
    "print(\"DataSet is complete\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# duration_from_1_seq_to_next = 60*15 # duration in seconds\n",
    "# filter_short_seq = 3 # remove the sequence whose size is less than 4\n",
    "# li_of_seqs,max_seq_len = getSequenceOfWholeData(df_rnn,duration_from_1_seq_to_next,filter_short_seq)\n",
    "# print(len(li_of_seqs))\n",
    "# print(li_of_seqs[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seq_len_2_count ={}\n",
    "# for seq in li_of_seqs:\n",
    "#     # seq = removeSameAlarms(seq)\n",
    "#     l = len(seq)\n",
    "#     seq_len_2_count[l] = 1+seq_len_2_count.get(l,0)\n",
    "\n",
    "# seq_len_2_count = {k:v for k,v in sorted(seq_len_2_count.items(), key=lambda t: t[1] )}\n",
    "# seq_len_2_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def removeSameAlarms(seq):\n",
    "#     new_seq = []\n",
    "\n",
    "#     new_seq.append(seq[0])\n",
    "\n",
    "#     for a in seq:\n",
    "\n",
    "#         if a == new_seq[-1]:\n",
    "#             continue\n",
    "#         new_seq.append(a)\n",
    "    \n",
    "#     return new_seq\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sum(seq_len_2_count.keys())/len(seq_len_2_count.keys())\n",
    "# l = 5*['5']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('base': conda)",
   "name": "python376jvsc74a57bd00a859b8847986444a92d0d4056d61d85cddcaed2326da9de26febc71b43395a3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}